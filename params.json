{
  "name": "Fast Predictive Image Registration",
  "tagline": "Source code for X. Yang et al., \"Fast Predictive Image Registration\"",
  "body": "This project page contains instructions to reproduce the results for our **initial paper**, \r\nas well as a tutorial on how to use this approach for your own registration tasks.\r\n\r\n## Paper\r\n\r\n**Fast Predictive Image Registration**    \r\nX. Yang (UNC Chapel Hill, USA)     \r\nR. Kwitt (University of Salzburg, Austria)    \r\nM. Niethammer (UNC Chapel Hill, USA)    \r\nMICCAI DLMI workshop (2016)    \r\n\r\n```bibtex\r\n@inproceedings{@YKM16a,\r\n    author    = {X. Yang and R. Kwitt and M. Niethammer},\r\n    title     = {Fast Predictive Image Registration},\r\n    booktitle = {DLMI},\r\n    year      = {2016}}        \r\n```\r\n\r\n## Requirements\r\n\r\nOur approach for momenta prediction is implemented in Torch. The actual mapping/warping of images (using the predicted momenta) is then realized using PyCA and VectorMomentum. Regaring minimum system requirements, we tested our code on Linux running Ubuntu 16.04 with 24GB of main memory and a NVIDIA Titan X (sponsored by NVIDIA, running CUDA 8.0). If the code runs on your system, please let us know your configuration and we are happy to add it to our list of supported platforms/configurations.\r\n\r\n* [Torch](http://torch.ch/)\r\n* [PyCA](https://bitbucket.org/scicompanat/pyca)\r\n* [Vector Momentum LDDMM](https://bitbucket.org/scicompanat/vectormomentum)\r\n* MATLAB (+ [Medical Image Processing Toolbox](https://www.mathworks.com/matlabcentral/fileexchange/41594-medical-image-processing-toolbox))    \r\n\r\n## Compilation\r\n\r\nFirst, lets assume that all of our code will resides under `code`. First, we are going to install PyCA. Due to compatibility issues between the latest Vector Momentum LDDMM package (which we will use) and PyCA, we suggest to checkout a old(er) version of PyCA. Note, that we also need the Insight Toolkit (ITK) to be installed.\r\n\r\n```bash\r\napt-get install insighttoolkit4-python libinsighttoolkit4-dev # install ITK\r\ncd /code/\r\ngit clone git@bitbucket.org:scicompanat/pyca.git\r\ncd ./pyca\r\ngit checkout 9954dd5319efaa0ac5f58977e57acf004ad73ed7\r\nmkdir Build\r\ncd Build\r\nccmake .. # configure PyCA via cmake curses interface\r\n```\r\n\r\nOn our system, we had to bump the `CUDA_ARCH_VERSION` to 20 for PyCA to compile. This can be done via the ccmake interface in the Advanced Mode. Also, the Python bindings did not compile with SWIG 3.0.3; we downgraded to swig-2.0.12 instead\r\n\r\n```bash\r\nsudo apt-get install swig2.0\r\n# you might have to uninstall swig3.0 if errors persist\r\n```\r\n\r\nThen, running\r\n\r\n```bash\r\ncd /code/pyca/Build\r\nmake -j4 # -j4 will run 4 parallel jobs\r\n```\r\n\r\nshould compile PyCA. Finally, we also set the `PYTHONPATH` as follows (we do recommend to put this into the .bashrc file, assuming that you run bash):\r\n\r\n```bash\r\nexport PYTHONPATH=${PYTHONPATH}:PATH_TO_PYCA/Build/python_module\r\n```\r\n\r\nwhere you have to (1) replace `PATH_TO_PYCA` with the name of the directory where you checked out PyCA (we assume that you built PyCA under PATH_TO_PYCA/Build). Next, we are going to clone the VectorMomentum LDDMM code and set the `PYTHONPATH` as before:\r\n\r\n```bash\r\ncd /code/\r\ngit clone https://bitbucket.org/scicompanat/vectormomentum.git\r\nexport PYTHONPATH=${PYTHONPATH}:/code/vectormomentum/Code/Python\r\n```\r\n\r\n## Installation\r\n\r\nJust clone the GitHub repository as:\r\n\r\n```bash\r\ncd /code/\r\ngit clone https://github.com/rkwitt/FastPredictiveImageRegistration.git\r\n```\r\n\r\n## **EXAMPLE 1**: 2D atlas-to-image registration\r\n\r\n![](https://rkwitt.github.io/FastPredictiveImageRegistration/images/montage2D.png)\r\n\r\nWe provide 2D example data (MR slices of OASIS) as well as a pretrained model in the repository under the `data` directory. This directory contains\r\n\r\n* 100 images (transversal slices) for training\r\n* 50 images (transversal slices) for testing\r\n* 1 atlas image\r\n\r\nAdditionally, the data directory contains computed target momenta for atlas-to-image registration which will be used for training our network. In case you don't want to use the pretrained model for experimenting, you can train your own network for momentum prediction with the provided data as follows:\r\n\r\n```bash\r\ncd /code/FastPredictiveImageRegistration\r\nth main_nodiff.lua\r\n```\r\n\r\nThe network definition for the particular model in this example can be found in the file `create_model.lua` (in the function `VAE_deformation_parallel_small_noDropout`). Per default, we train (using rmsprop) for 10 epochs using a batch size of 300 and 15x15 patches.\r\n\r\n### Momenta prediction by a trained model\r\n\r\nTo run the (pre)-trained model for momenta prediction, we simply execute\r\n\r\n```bash\r\ncd /code/FastPredictiveImageRegistration\r\nth test_recon_nodiff.lua\r\n```       \r\n\r\nIf this code fails since you do not have the matio module, install it with\r\n\r\n```bash\r\nluarocks install matio\r\n```\r\n        \r\nOnce, `test_recon_nodiff.lua` completes, you should see a file named `2D_output.mat` in the `/code/FastPredictiveImageRegistration` directory.\r\n\r\n### Warping images based on predicted momenta\r\n\r\nIn our code, we implement the warping step as follows: first, we will convert all momenta predictions to `.mhd` files; second, we prepare the configuration files for VectorMomentum LDDMM and eventually run geodesic shooting using the predicted momenta. Lets first start MATLAB and change to the utils directory:\r\n\r\n```matlab\r\ncd /code/FastPredictiveImageRegistration/utils\r\n```        \r\n\r\nThen, we edit the file `change_m0_to_mhd_2D.m` and set the corresponding paths. Per default, the output directory will be `/tmp/` and the predicted momenta files will be `/tmp/m_1.mhd` to `/tmp/m_50.mhd`, since we have N=50 test cases. Next, let us write the YAML configuration files for the VectorMomentum LDDMM code. This is done by editing `updateyaml.m`. Running `updateyaml` will then create N=50 configuration files in the output directory.\r\n\r\n```matlab\r\ncd /code/FastPredictiveImageRegistration/utils\r\ncchange_m0_to_mhd_2D\r\nupdateyaml\r\n```        \r\n\r\nNext, we can run the VectorMomentum LDDMM code (for our first test case in this example) as follows:\r\n\r\n```bash\r\ncd /external/vectormomentum/Code/Python/Applications/\r\npython CAvmGeodesicShooting.py ~/deformation-prediction-code/utils/deep_network_1.yaml\r\n```\r\n        \r\nThis will create the atlas image warped onto the source image in the directory `/tmp/case_1`. If running the geodesic shooting code produces errors (related to plotting), just comment out `GeodesicShootingPlots(g, ginv, I0, It, cf)` on line 151 of `CAvmGeodesicShooting.py`.\r\n\r\n## Contact\r\n\r\nPlease contact Xiao Yang for comments, suggestions or bug reports :)\r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}