<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Fast Predictive Image Registration by rkwitt</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Fast Predictive Image Registration</h1>
      <h2 class="project-tagline">Source code for X. Yang et al., &quot;Fast Predictive Image Registration&quot;</h2>
      <a href="https://github.com/rkwitt/FastPredictiveImageRegistration" class="btn">View on GitHub</a>
      <a href="https://github.com/rkwitt/FastPredictiveImageRegistration/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/rkwitt/FastPredictiveImageRegistration/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>This project page contains instructions to reproduce the results for our initial paper, as well as a tutorial on how to use 
this approach for your own registration tasks.</p>

<h3>
<a id="paper" class="anchor" href="#paper" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Paper</h3>

<p><strong>Fast Predictive Image Registration</strong><br>
X. Yang (UNC Chapel Hill, USA)<br>
R. Kwitt (University of Salzburg, Austria)<br>
M. Niethammer (UNC Chapel Hill, USA)<br>
MICCAI DLMI workshop (2016)    </p>

<pre lang="bibtex"><code>@inproceedings{@YKM16a,
    author    = {X. Yang and R. Kwitt and M. Niethammer},
    title     = {Fast Predictive Image Registration},
    booktitle = {DLMI},
    year      = {2016}}        
</code></pre>

<h3>
<a id="requirements" class="anchor" href="#requirements" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Requirements</h3>

<p>Our approach for momenta prediction is implemented in Torch. The actual mapping/warping of images (using the predicted momenta) is then realized using PyCA and VectorMomentum. Regaring minimum system requirements, we tested our code on Linux running Ubuntu 16.04 with 24GB of main memory and a NVIDIA Titan X (sponsored by NVIDIA, running CUDA 8.0). If the code runs on your system, please let us know your configuration and we are happy to add it to our list of supported platforms/configurations.</p>

<ul>
<li><a href="http://torch.ch/">Torch</a></li>
<li><a href="https://bitbucket.org/scicompanat/pyca">PyCA</a></li>
<li><a href="https://bitbucket.org/scicompanat/vectormomentum">Vector Momentum LDDMM</a></li>
<li>MATLAB (+ <a href="https://www.mathworks.com/matlabcentral/fileexchange/41594-medical-image-processing-toolbox">Medical Image Processing Toolbox</a>)<br>
</li>
</ul>

<h3>
<a id="compilation" class="anchor" href="#compilation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Compilation</h3>

<p>First, lets assume that all of our code will resides under <code>code</code>. First, we are going to install PyCA. Due to compatibility issues between the latest Vector Momentum LDDMM package (which we will use) and PyCA, we suggest to checkout a old(er) version of PyCA. Note, that we also need the Insight Toolkit (ITK) to be installed.</p>

<div class="highlight highlight-source-shell"><pre>apt-get install insighttoolkit4-python libinsighttoolkit4-dev <span class="pl-c"># install ITK</span>
<span class="pl-c1">cd</span> /code/
git clone git@bitbucket.org:scicompanat/pyca.git
<span class="pl-c1">cd</span> ./pyca
git checkout 9954dd5319efaa0ac5f58977e57acf004ad73ed7
mkdir Build
<span class="pl-c1">cd</span> Build
ccmake .. <span class="pl-c"># configure PyCA via cmake curses interface</span></pre></div>

<p>On our system, we had to bump the <code>CUDA_ARCH_VERSION</code> to 20 for PyCA to compile. This can be done via the ccmake interface in the Advanced Mode. Also, the Python bindings did not compile with SWIG 3.0.3; we downgraded to swig-2.0.12 instead</p>

<div class="highlight highlight-source-shell"><pre>sudo apt-get install swig2.0
<span class="pl-c"># you might have to uninstall swig3.0 if errors persist</span></pre></div>

<p>Then, running</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span> /code/pyca/Build
make -j4 <span class="pl-c"># -j4 will run 4 parallel jobs</span></pre></div>

<p>should compile PyCA. Finally, we also set the <code>PYTHONPATH</code> as follows (we do recommend to put this into the .bashrc file, assuming that you run bash):</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span> PYTHONPATH=<span class="pl-smi">${PYTHONPATH}</span>:PATH_TO_PYCA/Build/python_module</pre></div>

<p>where you have to (1) replace <code>PATH_TO_PYCA</code> with the name of the directory where you checked out PyCA (we assume that you built PyCA under PATH_TO_PYCA/Build). Next, we are going to clone the VectorMomentum LDDMM code and set the <code>PYTHONPATH</code> as before:</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span> /code/
git clone https://bitbucket.org/scicompanat/vectormomentum.git
<span class="pl-k">export</span> PYTHONPATH=<span class="pl-smi">${PYTHONPATH}</span>:/code/vectormomentum/Code/Python</pre></div>

<h3>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h3>

<p>Just clone the GitHub repository as:</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span> /code/
git clone https://github.com/rkwitt/FastPredictiveImageRegistration.git</pre></div>

<h3>
<a id="example-1-2d-atlas-to-image-registration" class="anchor" href="#example-1-2d-atlas-to-image-registration" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>EXAMPLE 1: 2D atlas-to-image registration</h3>

<p><img src="https://rkwitt.github.io/FastPredictiveImageRegistration/images/montage2D.png" alt=""></p>

<p>We provide 2D example data (MR slices of OASIS) as well as a pretrained model in the repository under the <code>data</code> directory. This directory contains</p>

<ul>
<li>100 images (transversal slices) for training</li>
<li>50 images (transversal slices) for testing</li>
<li>1 atlas image</li>
</ul>

<p>Additionally, the data directory contains computed target momenta for atlas-to-image registration which will be used for training our network. In case you don't want to use the pretrained model for experimenting, you can train your own network for momentum prediction with the provided data as follows:</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span> /code/FastPredictiveImageRegistration
th main_nodiff.lua</pre></div>

<p>The network definition for the particular model in this example can be found in the file <code>create_model.lua</code> (in the function <code>VAE_deformation_parallel_small_noDropout</code>). Per default, we train (using rmsprop) for 10 epochs using a batch size of 300 and 15x15 patches.</p>

<h4>
<a id="momenta-prediction-by-a-trained-model" class="anchor" href="#momenta-prediction-by-a-trained-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Momenta prediction by a trained model</h4>

<p>To run the (pre)-trained model for momenta prediction, we simply execute</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span> /code/FastPredictiveImageRegistration
th test_recon_nodiff.lua</pre></div>

<p>If this code fails since you do not have the matio module, install it with</p>

<div class="highlight highlight-source-shell"><pre>luarocks install matio</pre></div>

<p>Once, <code>test_recon_nodiff.lua</code> completes, you should see a file named <code>2D_output.mat</code> in the <code>/code/FastPredictiveImageRegistration</code> directory.</p>

<h4>
<a id="warping-images-based-on-predicted-momenta" class="anchor" href="#warping-images-based-on-predicted-momenta" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Warping images based on predicted momenta</h4>

<p>In our code, we implement the warping step as follows: first, we will convert all momenta predictions to <code>.mhd</code> files; second, we prepare the configuration files for VectorMomentum LDDMM and eventually run geodesic shooting using the predicted momenta. Lets first start MATLAB and change to the utils directory:</p>

<div class="highlight highlight-source-matlab"><pre><span class="pl-k">cd</span> /code/FastPredictiveImageRegistration/utils</pre></div>

<p>Then, we edit the file <code>change_m0_to_mhd_2D.m</code> and set the corresponding paths. Per default, the output directory will be <code>/tmp/</code> and the predicted momenta files will be <code>/tmp/m_1.mhd</code> to <code>/tmp/m_50.mhd</code>, since we have N=50 test cases. Next, let us write the YAML configuration files for the VectorMomentum LDDMM code. This is done by editing <code>updateyaml.m</code>. Running <code>updateyaml</code> will then create N=50 configuration files in the output directory.</p>

<div class="highlight highlight-source-matlab"><pre><span class="pl-k">cd</span> /code/FastPredictiveImageRegistration/utils
cchange_m0_to_mhd_2D
updateyaml</pre></div>

<p>Next, we can run the VectorMomentum LDDMM code (for our first test case in this example) as follows:</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span> /external/vectormomentum/Code/Python/Applications/
python CAvmGeodesicShooting.py <span class="pl-k">~</span>/deformation-prediction-code/utils/deep_network_1.yaml</pre></div>

<p>This will create the atlas image warped onto the source image in the directory <code>/tmp/case_1</code>. If running the geodesic shooting code produces errors (related to plotting), just comment out <code>GeodesicShootingPlots(g, ginv, I0, It, cf)</code> on line 151 of <code>CAvmGeodesicShooting.py</code>.</p>

<h3>
<a id="contact" class="anchor" href="#contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contact</h3>

<p>Please contact Xiao Yang for comments, suggestions or bug reports :)</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/rkwitt/FastPredictiveImageRegistration">Fast Predictive Image Registration</a> is maintained by <a href="https://github.com/rkwitt">rkwitt</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
